# validate_prompts_views.R
# ------------------------------------------------------------------
# One-file validator for prompt datasets.
# - File picker on source(); reads .xlsx/.xls (first sheet) or .csv
# - Validations open with View(); writes nothing to disk
# - Technique-based counts, missingness, near-dups, split leakage
# - Agreement (Direct vs Paraphrased) per model + inter-model agreement on PARAPHRASED
# - Console output is spaced for readability
# - Only the specific View() tables you requested are shown
# ------------------------------------------------------------------

# ---- Package setup ----
required_pkgs <- c(
  "readxl","dplyr","stringr","text2vec","Matrix","readr","tools",
  "irr","tibble"
)
to_install <- setdiff(required_pkgs, rownames(installed.packages()))
if (length(to_install) > 0) {
  message("Installing missing packages: ", paste(to_install, collapse = ", "))
  install.packages(to_install, repos = "https://cloud.r-project.org")
}

suppressPackageStartupMessages({
  library(readxl)
  library(dplyr)
  library(stringr)
  library(text2vec)
  library(Matrix)
  library(readr)
  library(tools)
  library(irr)
  library(tibble)
})

# ---- Helpers ----
is_text_series <- function(x) {
  if (!is.character(x)) return(FALSE)
  non_null <- x[!is.na(x)]
  if (length(non_null) == 0) return(FALSE)
  mean_len <- mean(nchar(non_null))
  whitespace_rate <- mean(stringr::str_detect(non_null, "\\s"))
  (mean_len > 20) || (whitespace_rate > 0.2)
}

read_dataset_auto <- function(path) {
  ext <- tolower(tools::file_ext(path))
  if (ext %in% c("xlsx","xls")) {
    sh <- readxl::excel_sheets(path)[1]
    df <- readxl::read_excel(path, sheet = sh, .name_repair = "minimal")
    df <- as.data.frame(df, stringsAsFactors = FALSE)
  } else if (ext %in% c("csv","txt")) {
    df <- readr::read_csv(path, show_col_types = FALSE, progress = FALSE)
    df <- as.data.frame(df, stringsAsFactors = FALSE)
  } else {
    stop("Unsupported file type: ", ext, ". Please select .xlsx, .xls, or .csv")
  }
  names(df) <- trimws(names(df))
  df[] <- lapply(df, function(col) if (is.factor(col)) as.character(col) else col)
  df
}

.num_or_na <- function(x) { if (is.null(x) || length(x) == 0) return(NA_real_) else as.numeric(x) }

compute_agreement <- function(a, b) {
  a <- as.character(a); b <- as.character(b)
  keep <- !(is.na(a) | is.na(b) | a == "" | b == "")
  a <- a[keep]; b <- b[keep]
  if (length(a) < 2) return(list(summary=NULL, confusion=NULL))
  labs <- sort(unique(c(a, b)))
  ta <- factor(a, levels = labs)
  tb <- factor(b, levels = labs)
  tab <- as.data.frame.matrix(table(ta, tb))
  agree <- sum(diag(as.matrix(tab))) / sum(as.matrix(tab))
  k <- tryCatch({ irr::kappa2(cbind(as.character(ta), as.character(tb)), weight = "unweighted") }, error = function(e) NULL)
  out <- data.frame(
    metric = c("n_pairs","percent_agreement","cohens_kappa","kappa_se","kappa_p_value"),
    value  = c(length(a),
               round(100*agree,2),
               round(if (!is.null(k)) .num_or_na(k$value) else NA_real_,4),
               round(if (!is.null(k)) .num_or_na(k$se)    else NA_real_,4),
               if (!is.null(k)) .num_or_na(k$p.value)     else NA_real_),
    stringsAsFactors = FALSE
  )
  list(summary = out, confusion = tab)
}

guess_result_columns <- function(df) {
  cols <- names(df)
  res_pat <- "(label|result|decision|outcome|class|verdict|judg(e)?ment|response|policy)"
  dir_pat <- "(^|[_\\-\\s])(direct|orig(inal)?)([_\\-\\s]|$)"
  par_pat <- "(^|[_\\-\\s])(para(phrase|phrased)?|paraphrased|rephrase(d)?)([_\\-\\s]|$)"
  res_cols <- cols[stringr::str_detect(tolower(cols), res_pat)]
  dir_cols <- res_cols[stringr::str_detect(tolower(res_cols), dir_pat)]
  par_cols <- res_cols[stringr::str_detect(tolower(res_cols), par_pat)]
  if (length(dir_cols) == 0 || length(par_cols) == 0) {
    if (length(res_cols) >= 2) {
      if (length(dir_cols) == 0) dir_cols <- res_cols[1]
      if (length(par_cols) == 0 && length(res_cols) >= 2) par_cols <- res_cols[2]
    }
  }
  list(direct = unique(dir_cols)[1], paraphrase = unique(par_cols)[1])
}

# ---- Main validator ----
validate_prompts_view <- function(df,
                                  rep_text_col = NULL,
                                  near_dup_threshold = 0.90,
                                  split_leak_threshold = 0.92) {
  # Identify prompt-like columns
  text_cols <- names(df)[vapply(df, is_text_series, logical(1))]
  priority_cols <- names(df)[stringr::str_detect(names(df), regex("prompt|text|instruction|input", ignore_case = TRUE))]
  prompt_like_cols <- intersect(priority_cols, text_cols)
  if (length(prompt_like_cols) == 0) prompt_like_cols <- head(text_cols, 2)
  if (is.null(rep_text_col)) {
    if (length(prompt_like_cols) >= 1) rep_text_col <- prompt_like_cols[1]
    else stop("No text-like columns found. Please ensure at least one prompt/text column is character type.")
  }
  
  # Schema & Missingness (NA-only)
  schema <- data.frame(
    column   = names(df),
    dtype    = vapply(df, function(x) class(x)[1], character(1)),
    non_null = vapply(df, function(x) sum(!is.na(x)), integer(1)),
    nulls    = vapply(df, function(x) sum(is.na(x)), integer(1)),
    stringsAsFactors = FALSE
  )
  schema$null_pct <- round(100 * schema$nulls / pmax(1, (schema$non_null + schema$nulls)), 2)
  missingness <- schema %>% dplyr::select(column, null_pct) %>% dplyr::arrange(dplyr::desc(null_pct))
  
  # Strict missingness (also used to list missing rows)
  is_missing_strict <- function(v) { v <- as.character(v); v[is.na(v)] <- ""; stringr::str_trim(v) == "" }
  missing_rows_long <- dplyr::bind_rows(lapply(names(df), function(col) {
    v <- df[[col]]; miss <- is_missing_strict(v)
    if (!any(miss)) return(NULL)
    data.frame(
      column = col,
      row_index = which(miss) - 1,
      value_preview = substr(as.character(replace(v, is.na(v), ""))[miss], 1, 200),
      stringsAsFactors = FALSE
    )
  }))
  if (is.null(missing_rows_long)) missing_rows_long <- data.frame(column=character(), row_index=integer(), value_preview=character(), stringsAsFactors = FALSE)
  
  # Exact duplicates across main text fields
  exact_duplicates <- data.frame()
  if (length(prompt_like_cols) > 0) {
    key <- apply(df[prompt_like_cols], 1, function(row) paste(row, collapse = " || "))
    dup_mask <- duplicated(key) | duplicated(key, fromLast = TRUE)
    if (any(dup_mask, na.rm = TRUE)) {
      exact_duplicates <- data.frame(
        row_index = which(dup_mask) - 1,
        group_id  = as.integer(factor(key[dup_mask])) - 1,
        preview   = substr(key[dup_mask], 1, 200),
        stringsAsFactors = FALSE
      ) %>% dplyr::arrange(group_id, row_index)
    }
  }
  
  # Near-duplicates on representative prompt column
  near_duplicates <- data.frame()
  if (!is.null(rep_text_col)) {
    texts <- df[[rep_text_col]]; texts <- if (is.character(texts)) texts else as.character(texts); texts[is.na(texts)] <- ""
    norm <- tolower(stringr::str_squish(texts))
    if (length(norm) > 1 && any(nchar(norm) > 0)) {
      it <- text2vec::itoken(norm, progressbar = FALSE)
      vocab <- text2vec::create_vocabulary(it, ngram = c(3L, 6L), stopwords = character(0))
      dtm <- text2vec::create_dtm(it, text2vec::vocab_vectorizer(vocab))
      if (nrow(dtm) > 1) {
        sim <- text2vec::sim2(dtm, method = "cosine", norm = "l2")
        coords <- which(sim >= near_dup_threshold, arr.ind = TRUE)
        coords <- coords[coords[,1] < coords[,2], , drop = FALSE]
        if (nrow(coords) > 0) {
          near_duplicates <- data.frame(
            i = coords[,1] - 1,
            j = coords[,2] - 1,
            cosine_sim = sim[coords],
            i_preview = substr(texts[coords[,1]], 1, 200),
            j_preview = substr(texts[coords[,2]], 1, 200),
            stringsAsFactors = FALSE
          ) %>% dplyr::arrange(dplyr::desc(cosine_sim))
        }
      }
    }
  }
  
  # Length outliers (z > 3)
  length_outliers <- data.frame()
  if (length(prompt_like_cols) > 0) {
    for (c in prompt_like_cols) {
      s <- df[[c]]; s <- if (is.character(s)) s else as.character(s); s[is.na(s)] <- ""
      nchar_vec <- nchar(s); sdv <- stats::sd(nchar_vec)
      if (sdv > 0) {
        z <- (nchar_vec - mean(nchar_vec)) / sdv; idx <- which(z > 3)
        if (length(idx) > 0) {
          length_outliers <- dplyr::bind_rows(length_outliers, data.frame(
            column = c, row_index = idx - 1, char_len = nchar_vec[idx],
            preview = substr(s[idx], 1, 200), stringsAsFactors = FALSE
          ))
        }
      }
    }
  }
  
  # Technique coverage
  category_counts <- data.frame()
  technique_cols <- names(df)[stringr::str_detect(names(df), regex("\\btechnique\\b", ignore_case = TRUE))]
  if (length(technique_cols) > 0) {
    tech_col <- technique_cols[1]
    techs <- as.character(df[[tech_col]])
    category_counts <- as.data.frame(table(techs), stringsAsFactors = FALSE) %>%
      dplyr::arrange(dplyr::desc(Freq)) %>% dplyr::rename(!!tech_col := techs, count = Freq)
  }
  
  # Paired-field identical (first two prompt-like columns)
  paired_field_check <- data.frame()
  if (length(prompt_like_cols) >= 2) {
    a <- prompt_like_cols[1]; b <- prompt_like_cols[2]
    A <- df[[a]]; B <- df[[b]]
    A <- tolower(stringr::str_trim(replace(if (is.character(A)) A else as.character(A), is.na(A), "")))
    B <- tolower(stringr::str_trim(replace(if (is.character(B)) B else as.character(B), is.na(B), "")))
    eq <- sum(A == B)
    paired_field_check <- data.frame(
      field_A = a, field_B = b,
      identical_pairs = eq,
      total_pairs_checked = nrow(df),
      identical_pct = round(100 * eq / max(1, nrow(df)), 2),
      stringsAsFactors = FALSE
    )
  }
  
  # Paraphrased exact duplicate PAIRS (counts & rows)
  paraphrase_exact_duplicates <- data.frame()
  paraphrase_exact_duplicate_pairs_count <- data.frame(metric = "paraphrase_exact_duplicate_pairs", value = 0)
  para_text_candidates <- names(df)[stringr::str_detect(names(df), regex("para(phrase|phrased)?|paraphrased|rephrase(d)?", ignore_case = TRUE))]
  para_text_col <- intersect(para_text_candidates, text_cols)
  if (length(para_text_col) > 0) {
    para_col <- para_text_col[1]
    vals <- df[[para_col]]; vals <- if (is.character(vals)) vals else as.character(vals); vals[is.na(vals)] <- ""
    key <- vals
    dup_mask <- duplicated(key) | duplicated(key, fromLast = TRUE)
    if (any(dup_mask, na.rm = TRUE)) {
      paraphrase_exact_duplicates <- data.frame(
        row_index = which(dup_mask) - 1,
        group_key = key[dup_mask],
        stringsAsFactors = FALSE
      ) %>% dplyr::mutate(group_id = as.integer(factor(group_key)) - 1) %>%
        dplyr::select(row_index, group_id, group_key) %>% dplyr::arrange(group_id, row_index)
      group_sizes <- table(factor(key[dup_mask]))
      pairs_count <- sum(choose(as.integer(group_sizes), 2))
      paraphrase_exact_duplicate_pairs_count$value <- pairs_count
    }
  }
  
  # Split leakage
  cross_split_near_dups <- data.frame()
  split_cols <- names(df)[stringr::str_detect(names(df), regex("\\b(split|fold|partition|set)\\b", ignore_case = TRUE))]
  split_status_msg <- ""
  if (!is.null(rep_text_col) && length(split_cols) > 0) {
    split_col <- split_cols[1]
    texts <- df[[rep_text_col]]; texts <- if (is.character(texts)) texts else as.character(texts)
    texts <- tolower(stringr::str_squish(replace(texts, is.na(texts), "")))
    if (length(texts) > 1 && any(nchar(texts) > 0)) {
      it <- text2vec::itoken(texts, progressbar = FALSE)
      vocab <- text2vec::create_vocabulary(it, ngram = c(3L, 6L), stopwords = character(0))
      dtm <- text2vec::create_dtm(it, text2vec::vocab_vectorizer(vocab))
      if (nrow(dtm) > 1) {
        sim <- text2vec::sim2(dtm, method = "cosine", norm = "l2")
        coords <- which(sim >= split_leak_threshold, arr.ind = TRUE)
        coords <- coords[coords[,1] < coords[,2], , drop = FALSE]
        if (nrow(coords) > 0) {
          splits <- as.character(df[[split_col]])
          keep <- splits[coords[,1]] != splits[coords[,2]]
          coords <- coords[keep, , drop = FALSE]
          if (nrow(coords) > 0) {
            cross_split_near_dups <- data.frame(
              i = coords[,1] - 1, i_split = splits[coords[,1]],
              j = coords[,2] - 1, j_split = splits[coords[,2]],
              cosine_sim = sim[coords], stringsAsFactors = FALSE
            ) %>% dplyr::arrange(dplyr::desc(cosine_sim))
          }
        }
      }
    }
    split_status_msg <- paste0("Split leakage check: split column = '", split_col,
                               "', threshold = ", split_leak_threshold,
                               ", pairs found = ", nrow(cross_split_near_dups))
  } else {
    split_status_msg <- "Split leakage check: NO split/fold/set column found (check skipped)."
  }
  
  # Auto-detected agreement (fallback)
  ira_cols <- guess_result_columns(df)
  ira_summary <- data.frame(); ira_confusion <- data.frame()
  if (!is.null(ira_cols$direct) && !is.null(ira_cols$paraphrase) &&
      ira_cols$direct %in% names(df) && ira_cols$paraphrase %in% names(df)) {
    res <- compute_agreement(df[[ira_cols$direct]], df[[ira_cols$paraphrase]])
    if (!is.null(res$summary)) ira_summary <- res$summary
    if (!is.null(res$confusion)) {
      ira_confusion <- tibble::as_tibble(
        tibble::rownames_to_column(as.data.frame(res$confusion), var = "direct\\paraphrase")
      )
    }
  }
  
  # Direct vs Paraphrased per model
  ira_summary_Grok <- ira_confusion_Grok <- ira_summary_GPT5 <- ira_confusion_GPT5 <- ira_summary_Gemini <- ira_confusion_Gemini <- data.frame()
  model_result_pairs <- list(
    Grok   = list(direct = "Test Result Grok - Direct",    paraphrase = "Test Result Grok - paraphrased"),
    GPT5   = list(direct = "Test Result (GPT-5) - Direct", paraphrase = "Test Result (GPT-5) - paraphrased"),
    Gemini = list(direct = "Test Result Gemini - Direct",  paraphrase = "Test Result Gemini - paraphrased")
  )
  for (m in names(model_result_pairs)) {
    cols <- model_result_pairs[[m]]
    if (all(c(cols$direct, cols$paraphrase) %in% names(df))) {
      res <- compute_agreement(df[[cols$direct]], df[[cols$paraphrase]])
      if (!is.null(res$summary)) {
        summ <- res$summary
        summ <- data.frame(metric = c("model", as.character(summ$metric)),
                           value  = c(m, as.character(summ$value)),
                           stringsAsFactors = FALSE)
        if (m == "Grok")   ira_summary_Grok <- summ
        if (m == "GPT5")   ira_summary_GPT5 <- summ
        if (m == "Gemini") ira_summary_Gemini <- summ
      }
      if (!is.null(res$confusion)) {
        conf <- tibble::as_tibble(tibble::rownames_to_column(as.data.frame(res$confusion), var = "direct\\paraphrase"))
        if (m == "Grok")   ira_confusion_Grok <- conf
        if (m == "GPT5")   ira_confusion_GPT5 <- conf
        if (m == "Gemini") ira_confusion_Gemini <- conf
      }
    }
  }
  
  # Inter-model agreement on PARAPHRASED results
  inter_pairs <- list(
    "Grok_vs_GPT5"   = c("Test Result Grok - paraphrased",   "Test Result (GPT-5) - paraphrased"),
    "Grok_vs_Gemini" = c("Test Result Grok - paraphrased",   "Test Result Gemini - paraphrased"),
    "GPT5_vs_Gemini" = c("Test Result (GPT-5) - paraphrased","Test Result Gemini - paraphrased")
  )
  inter_summaries <- list(); inter_confusions <- list()
  for (nm in names(inter_pairs)) {
    pair <- inter_pairs[[nm]]
    if (all(pair %in% names(df))) {
      res <- compute_agreement(df[[pair[1]]], df[[pair[2]]])
      if (!is.null(res$summary)) inter_summaries[[nm]] <- res$summary %>% dplyr::mutate(pair = nm, .before = 1)
      if (!is.null(res$confusion)) inter_confusions[[nm]] <- tibble::as_tibble(
        tibble::rownames_to_column(as.data.frame(res$confusion), var = paste0(nm, " : left\\right"))
      )
    }
  }
  inter_summary_tbl <- if (length(inter_summaries)) dplyr::bind_rows(inter_summaries) else data.frame()
  inter_confusion_tbls <- inter_confusions
  
  # ---- Console summary (spaced) ----
  cat("Rows:", nrow(df), "  Columns:", ncol(df), "\n\n")
  cat("Exact duplicate rows (across main text fields):", if (nrow(exact_duplicates)>0) length(unique(exact_duplicates$row_index)) else 0, "\n")
  cat("Near-duplicate pairs:", if (nrow(near_duplicates)>0) nrow(near_duplicates) else 0, "\n")
  cat("Length outlier rows:", if (nrow(length_outliers)>0) length(unique(length_outliers$row_index)) else 0, "\n\n")
  cat(split_status_msg, "\n\n")
  cat("Paraphrased exact-duplicate PAIRS:", paraphrase_exact_duplicate_pairs_count$value, "\n\n")
  
  if (nrow(ira_summary) > 0) cat("Auto-detected Direct vs Paraphrased agreement pairs:", ira_summary$value[ira_summary$metric=="n_pairs"], "\n\n")
  if (nrow(ira_summary_Grok) > 0)   cat("Grok   (Direct vs Paraphrased) agreement pairs:",   ira_summary_Grok$value[ira_summary_Grok$metric=="n_pairs"], "\n")
  if (nrow(ira_summary_GPT5) > 0)   cat("GPT-5  (Direct vs Paraphrased) agreement pairs:",   ira_summary_GPT5$value[ira_summary_GPT5$metric=="n_pairs"], "\n")
  if (nrow(ira_summary_Gemini) > 0) cat("Gemini (Direct vs Paraphrased) agreement pairs:",   ira_summary_Gemini$value[ira_summary_Gemini$metric=="n_pairs"], "\n")
  cat("\n")
  if (nrow(inter_summary_tbl) > 0) {
    cat("Inter-model agreement on PARAPHRASED results:\n")
    for (nm in unique(inter_summary_tbl$pair)) {
      sub <- inter_summary_tbl[inter_summary_tbl$pair == nm, , drop = FALSE]
      cat(sprintf("  %s -> n=%s | %%agree=%s | kappa=%s\n",
                  nm,
                  sub$value[sub$metric=="n_pairs"],
                  sub$value[sub$metric=="percent_agreement"],
                  sub$value[sub$metric=="cohens_kappa"]))
    }
    cat("\n")
  }
  
  # ---- ONLY the requested View() tables ----
  View(schema)
  View(missingness)
  View(missing_rows_long)
  View(category_counts)
  View(exact_duplicates)
  View(near_duplicates)
  View(length_outliers)
  View(paired_field_check)
  View(cross_split_near_dups)
  View(paraphrase_exact_duplicate_pairs_count)
  View(paraphrase_exact_duplicates)
  View(ira_summary_Grok)
  View(ira_confusion_Grok)
  View(ira_summary_GPT5)
  View(ira_confusion_GPT5)
  View(ira_summary_Gemini)
  View(ira_confusion_Gemini)
  View(inter_summary_tbl)
  if (length(inter_confusion_tbls) > 0) { for (nm in names(inter_confusion_tbls)) View(inter_confusion_tbls[[nm]]) }
  
  invisible(list(
    schema = schema,
    missingness = missingness,
    missing_rows_long = missing_rows_long,
    technique_counts = category_counts,
    exact_duplicates = exact_duplicates,
    near_duplicates = near_duplicates,
    length_outliers = length_outliers,
    paired_field_check = paired_field_check,
    cross_split_near_dups = cross_split_near_dups,
    paraphrase_exact_duplicate_pairs_count = paraphrase_exact_duplicate_pairs_count,
    paraphrase_exact_duplicates = paraphrase_exact_duplicates,
    ira_summary_Grok = ira_summary_Grok,
    ira_confusion_Grok = ira_confusion_Grok,
    ira_summary_GPT5 = ira_summary_GPT5,
    ira_confusion_GPT5 = ira_confusion_GPT5,
    ira_summary_Gemini = ira_summary_Gemini,
    ira_confusion_Gemini = ira_confusion_Gemini,
    inter_model_paraphrase_summary = inter_summary_tbl,
    inter_model_paraphrase_confusions = inter_confusion_tbls,
    prompt_like_cols = prompt_like_cols,
    rep_text_col = rep_text_col
  ))
}

# ---- Interactive runner ----
try({
  message("Select your dataset (.xlsx/.xls or .csv) ...")
  path <- file.choose()
  message("Reading: ", path)
  df <- read_dataset_auto(path)
  results <- validate_prompts_view(df,
                                   rep_text_col = NULL,
                                   near_dup_threshold = 0.90,
                                   split_leak_threshold = 0.92)
}, silent = FALSE)
